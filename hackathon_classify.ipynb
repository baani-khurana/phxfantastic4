{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import keras\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>UPA</th>\n",
       "      <th>EventDate</th>\n",
       "      <th>Employer</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Nature</th>\n",
       "      <th>NatureTitle</th>\n",
       "      <th>Part of Body</th>\n",
       "      <th>Part of Body Title</th>\n",
       "      <th>Event</th>\n",
       "      <th>EventTitle</th>\n",
       "      <th>Source</th>\n",
       "      <th>SourceTitle</th>\n",
       "      <th>Secondary Source</th>\n",
       "      <th>Secondary Source Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015010015</td>\n",
       "      <td>931176</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>FCI Otisville Federal Correctional Institution</td>\n",
       "      <td>Two Mile Drive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTISVILLE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>10963.0</td>\n",
       "      <td>41.46</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>Fractures</td>\n",
       "      <td>513</td>\n",
       "      <td>Lower</td>\n",
       "      <td>1214</td>\n",
       "      <td>Injured by physical contact with person while ...</td>\n",
       "      <td>5721</td>\n",
       "      <td>Co-worker</td>\n",
       "      <td>5772.0</td>\n",
       "      <td>Inmate or detainee in custody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015010016</td>\n",
       "      <td>930267</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Kalahari Manufacturing LLC</td>\n",
       "      <td>171 Progress Drive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAKE DELTON</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>53940.0</td>\n",
       "      <td>43.59</td>\n",
       "      <td>...</td>\n",
       "      <td>1522</td>\n",
       "      <td>Second degree heat (thermal) burns</td>\n",
       "      <td>519</td>\n",
       "      <td>Leg(s)</td>\n",
       "      <td>317</td>\n",
       "      <td>Ignition of vapors, gases, or liquids</td>\n",
       "      <td>7261</td>\n",
       "      <td>Welding, cutting, and blow torches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015010018</td>\n",
       "      <td>929823</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Schneider National Bulk Carrier</td>\n",
       "      <td>420 CORAOPOLIS ROAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORAOPOLIS</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>15108.0</td>\n",
       "      <td>40.49</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Traumatic injuries and disorders, unspecified</td>\n",
       "      <td>9999</td>\n",
       "      <td>Nonclassifiable</td>\n",
       "      <td>4331</td>\n",
       "      <td>Other fall to lower level less than 6 feet</td>\n",
       "      <td>8421</td>\n",
       "      <td>Semi, tractor-trailer, tanker truck</td>\n",
       "      <td>741.0</td>\n",
       "      <td>Ladders-fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015010019</td>\n",
       "      <td>929711</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>PEPSI BOTTLING GROUP INC.</td>\n",
       "      <td>4541 HOUSTON AVE.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MACON</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>31206.0</td>\n",
       "      <td>32.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1972</td>\n",
       "      <td>Soreness, pain, hurt-nonspecified injury</td>\n",
       "      <td>510</td>\n",
       "      <td>Leg(s)</td>\n",
       "      <td>640</td>\n",
       "      <td>Caught in or compressed by equipment or object...</td>\n",
       "      <td>8623</td>\n",
       "      <td>Pallet jack-powered</td>\n",
       "      <td>8420.0</td>\n",
       "      <td>Truck-motorized freight hauling and utility, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015010020</td>\n",
       "      <td>929642</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>North American Pipe Corporation</td>\n",
       "      <td>210 South Arch Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JANESVILLE</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>53545.0</td>\n",
       "      <td>42.67</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>Fractures</td>\n",
       "      <td>4429</td>\n",
       "      <td>Finger(s)</td>\n",
       "      <td>6411</td>\n",
       "      <td>Caught in running equipment or machinery durin...</td>\n",
       "      <td>350</td>\n",
       "      <td>Metal, woodworking, and special material machi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID     UPA EventDate  \\\n",
       "0  2015010015  931176  1/1/2015   \n",
       "1  2015010016  930267  1/1/2015   \n",
       "2  2015010018  929823  1/1/2015   \n",
       "3  2015010019  929711  1/1/2015   \n",
       "4  2015010020  929642  1/1/2015   \n",
       "\n",
       "                                         Employer               Address1  \\\n",
       "0  FCI Otisville Federal Correctional Institution         Two Mile Drive   \n",
       "1                      Kalahari Manufacturing LLC     171 Progress Drive   \n",
       "2                 Schneider National Bulk Carrier    420 CORAOPOLIS ROAD   \n",
       "3                       PEPSI BOTTLING GROUP INC.      4541 HOUSTON AVE.   \n",
       "4                 North American Pipe Corporation  210 South Arch Street   \n",
       "\n",
       "  Address2         City         State      Zip  Latitude  \\\n",
       "0      NaN    OTISVILLE      NEW YORK  10963.0     41.46   \n",
       "1      NaN  LAKE DELTON     WISCONSIN  53940.0     43.59   \n",
       "2      NaN   CORAOPOLIS  PENNSYLVANIA  15108.0     40.49   \n",
       "3      NaN        MACON       GEORGIA  31206.0     32.77   \n",
       "4      NaN   JANESVILLE     WISCONSIN  53545.0     42.67   \n",
       "\n",
       "                         ...                          Nature  \\\n",
       "0                        ...                             111   \n",
       "1                        ...                            1522   \n",
       "2                        ...                              10   \n",
       "3                        ...                            1972   \n",
       "4                        ...                             111   \n",
       "\n",
       "                                     NatureTitle  Part of Body  \\\n",
       "0                                      Fractures           513   \n",
       "1             Second degree heat (thermal) burns           519   \n",
       "2  Traumatic injuries and disorders, unspecified          9999   \n",
       "3       Soreness, pain, hurt-nonspecified injury           510   \n",
       "4                                      Fractures          4429   \n",
       "\n",
       "   Part of Body Title  Event  \\\n",
       "0               Lower   1214   \n",
       "1              Leg(s)    317   \n",
       "2     Nonclassifiable   4331   \n",
       "3              Leg(s)    640   \n",
       "4           Finger(s)   6411   \n",
       "\n",
       "                                          EventTitle  Source  \\\n",
       "0  Injured by physical contact with person while ...    5721   \n",
       "1              Ignition of vapors, gases, or liquids    7261   \n",
       "2         Other fall to lower level less than 6 feet    8421   \n",
       "3  Caught in or compressed by equipment or object...    8623   \n",
       "4  Caught in running equipment or machinery durin...     350   \n",
       "\n",
       "                                         SourceTitle  Secondary Source  \\\n",
       "0                                          Co-worker            5772.0   \n",
       "1                 Welding, cutting, and blow torches               NaN   \n",
       "2                Semi, tractor-trailer, tanker truck             741.0   \n",
       "3                                Pallet jack-powered            8420.0   \n",
       "4  Metal, woodworking, and special material machi...               NaN   \n",
       "\n",
       "                              Secondary Source Title  \n",
       "0                      Inmate or detainee in custody  \n",
       "1                                                NaN  \n",
       "2                                      Ladders-fixed  \n",
       "3  Truck-motorized freight hauling and utility, u...  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('severeinjury.csv')\n",
    "df['Part of Body Title'] = [e.split()[0] for e in df['Part of Body Title']]\n",
    "df['Part of Body Title'] = [e.replace(',','') for e in df['Part of Body Title']]\n",
    "df['NatureTitle'] = [e.split()[0] for e in df['NatureTitle']]\n",
    "df['NatureTitle'] = [e.replace(',','') for e in df['NatureTitle']]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dirty = df['Final Narrative']\n",
    "y_body_dirty = df['Part of Body Title']\n",
    "y_nature_dirty = df['NatureTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.array(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translations...\n",
      "Lowercasing...\n",
      "Splitting...\n",
      "Fitting....\n",
      "[====================] 100.0%\n",
      "Done fitting!\n",
      "Sequencing....\n",
      "[====================] 100.0%\n",
      "Finished Tokening!\n"
     ]
    }
   ],
   "source": [
    "def clean_sentences(sentences):\n",
    "    translator = str.maketrans('', '', string.punctuation + string.digits)\n",
    "    print('Starting translations...')\n",
    "    sentences = [s.translate(translator) for s in sentences]\n",
    "    stopset = set(nltk.corpus.stopwords.words('english'))\n",
    "    print('Lowercasing...')\n",
    "    tokens = [nltk.wordpunct_tokenize(s.lower()) for s in sentences]\n",
    "    print('Splitting...')\n",
    "    tokens = [np.array(t)[np.invert(np.isin(t, list(stopset)))] for t in tokens]\n",
    "    return np.array(tokens)\n",
    "\n",
    "tokens = clean_sentences(X_dirty)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=1000, oov_token=1)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "    \n",
    "X_all = []\n",
    "\n",
    "count = 0\n",
    "print('Fitting....')\n",
    "for line in tokens:\n",
    "    tokenizer.fit_on_texts(line)\n",
    "    count += 1\n",
    "    if count % 100 == 0 or count == len(X_dirty):\n",
    "        if count != 0:\n",
    "            sys.stdout.write('\\r')\n",
    "        bars = int(count/len(X_dirty)*20)\n",
    "        sys.stdout.write('[{0:20}] {1:4.1%}'.format('='*bars, count/len(X_dirty)))\n",
    "print('\\nDone fitting!')\n",
    "print('Sequencing....')\n",
    "count = 0\n",
    "for line in tokens:\n",
    "    add = [list(np.array(tokenizer.texts_to_sequences(line)).flatten())]\n",
    "    X_all += add\n",
    "    count += 1\n",
    "    if count % 100 == 0 or count == len(X_dirty):\n",
    "        if count != 0:\n",
    "            sys.stdout.write('\\r')\n",
    "        bars = int(count/len(X_dirty)*20)\n",
    "        sys.stdout.write('[{0:20}] {1:4.1%}'.format('='*bars, count/len(X_dirty)))\n",
    "print('\\nFinished Tokening!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Vocab.dat', 'w') as vfile:\n",
    "    vfile.write('{} {}'.format(0, 'x'))\n",
    "    for key, value in sorted(tokenizer.word_index.items(),\n",
    "                                 key=lambda kv: (kv[1], kv[0])):\n",
    "        vfile.write('\\n{} {}'.format(value, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_dict():\n",
    "    vocab_dict = {}\n",
    "    with open('Vocab.dat') as vocab_file:\n",
    "        for line in vocab_file:\n",
    "            (val, key) = line.split()\n",
    "            val = int(val)\n",
    "            if val == 0:\n",
    "                key = ''\n",
    "            vocab_dict[key] = val\n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence_from_dict(sentence, vocab_dict):\n",
    "    tokenized = []\n",
    "    for word in sentence.split():\n",
    "        if word in vocab_dict:\n",
    "            tokenized += [vocab_dict[word]]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_sentence(model, sentence):\n",
    "    vocab_dict = get_vocab_dict()\n",
    "    tokenized = tokenize_sentence_from_dict(sentence, vocab_dict)\n",
    "    return model.predict(np.array([tokenized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([134, 6827, 437, 2171, 5315, 5316, 5317, 4527, 2334, 65, 6828, 46, 1299, 953, 34, 2171, 2334, 2, 40, 6829, 4, 14, 48, 442, 547, 70, 379, 1223, 588])\n",
      " list([1, 9, 534, 125, 87, 138, 75, 17, 216, 800, 28, 862])\n",
      " list([13, 234, 2, 22, 21, 272, 904, 58, 20, 1, 1204, 173, 2891, 838, 4528])\n",
      " ...\n",
      " list([1, 50, 1116, 134, 255, 1461, 430, 835, 440, 625, 149, 2, 7, 27, 260, 442])\n",
      " list([1, 7, 949, 1198, 1954, 32, 401, 327])\n",
      " list([1, 78, 1471, 627, 85, 2073, 630, 627, 22, 859, 351, 1069, 95, 133, 11610, 368, 502, 627, 2, 40, 1, 625, 1724, 324, 72, 43, 5, 4, 14])]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_all = np.load('X_all.npy')\n",
    "#y_all = np.load('y_all.npy')\n",
    "\n",
    "X_all = keras.preprocessing.sequence.pad_sequences(X_all, 40)\n",
    "y_body_all = np.array(pd.get_dummies(y_body_dirty))\n",
    "y_nature_all = np.array(pd.get_dummies(y_nature_dirty))\n",
    "\n",
    "np.save('X_all.npy', X_all)\n",
    "np.save('y_body_all.npy', y_body_all)\n",
    "np.save('y_nature_all.npy', y_nature_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(X_all)))\n",
    "np.random.shuffle(indices)\n",
    "num_train = int(.75*len(X_all))\n",
    "\n",
    "X_train = X_all[indices[:num_train]]\n",
    "X_test = X_all[indices[num_train:]]\n",
    "y_body_train = y_body_all[indices[:num_train]]\n",
    "y_body_test = y_body_all[indices[num_train:]]\n",
    "y_nature__train = y_nature__all[indices[:num_train]]\n",
    "y_nature__test = y_nature__all[indices[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_output):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Embedding(12000, 50, mask_zero=True))\n",
    "    model.add(keras.layers.LSTM(64))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(keras.layers.Dense(num_output, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )   \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16183 samples, validate on 5395 samples\n",
      "Epoch 1/10\n",
      "16183/16183 [==============================] - 37s 2ms/step - loss: 2.2157 - acc: 0.3909 - val_loss: 1.3317 - val_acc: 0.6536\n",
      "Epoch 2/10\n",
      "16183/16183 [==============================] - 35s 2ms/step - loss: 1.0781 - acc: 0.7161 - val_loss: 0.9294 - val_acc: 0.7592\n",
      "Epoch 3/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.7361 - acc: 0.8042 - val_loss: 0.8213 - val_acc: 0.7842\n",
      "Epoch 4/10\n",
      "16183/16183 [==============================] - 40s 2ms/step - loss: 0.5550 - acc: 0.8498 - val_loss: 0.7886 - val_acc: 0.8030\n",
      "Epoch 5/10\n",
      "16183/16183 [==============================] - 36s 2ms/step - loss: 0.4442 - acc: 0.8789 - val_loss: 0.7918 - val_acc: 0.8030\n",
      "Epoch 6/10\n",
      "16183/16183 [==============================] - 35s 2ms/step - loss: 0.3572 - acc: 0.9013 - val_loss: 0.8375 - val_acc: 0.8011\n",
      "Epoch 7/10\n",
      "16183/16183 [==============================] - 36s 2ms/step - loss: 0.2898 - acc: 0.9173 - val_loss: 0.8980 - val_acc: 0.8019\n",
      "Epoch 8/10\n",
      "16183/16183 [==============================] - 36s 2ms/step - loss: 0.2407 - acc: 0.9328 - val_loss: 0.9577 - val_acc: 0.7948\n",
      "Epoch 9/10\n",
      "16183/16183 [==============================] - 36s 2ms/step - loss: 0.2099 - acc: 0.9414 - val_loss: 0.9498 - val_acc: 0.7963\n",
      "Epoch 10/10\n",
      "16183/16183 [==============================] - 36s 2ms/step - loss: 0.1733 - acc: 0.9494 - val_loss: 1.0377 - val_acc: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f361e8a7278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_body = build_model(len(pd.get_dummies(y_body_dirty).columns))\n",
    "model_body.fit(X_train, y_body_train, validation_data=(X_test, y_body_test), epochs=10)\n",
    "\n",
    "model_nature = build_model(len(pd.get_dummies(y_nature_dirty).columns))\n",
    "model_nature.fit(X_train, y_nature_train, validation_data=(X_test, y_nature_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_body.save(\"body_parts2.h5\")\n",
    "model_nature.save(\"nature.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \n",
      "\n",
      "An excavator was dislodged from a flatbed trailer after hitting an overpass on Northbound I-15. An employee attempted to reload the excavator onto the trailer.  The excavator encountered fluid on the flatbed and slipped off the trailer. The employee was injured, sustaining a hairline fracture to the neck vertebrae.\n",
      "\n",
      "Prediction: \n",
      "Neck\n",
      "\n",
      "Actual: \n",
      "Neck\n"
     ]
    }
   ],
   "source": [
    "#6405\n",
    "test_sentence = df['Final Narrative'][6410]\n",
    "#test_sentence = 'The employee fell off of the ladder and hit his head.'\n",
    "print(\"Sentence: \\n\\n{}\".format(test_sentence))\n",
    "model = keras.models.load_model(\"body_parts.h5\")\n",
    "pred = predict_from_sentence(model, test_sentence)\n",
    "idx = np.argmax(pred)\n",
    "print(\"\\nPrediction: \\n{}\".format(pd.get_dummies(y_dirty).columns[idx]))\n",
    "print(\"\\nActual: \\n{}\".format(df['Part of Body Title'][6410]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ankle(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arch(es)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arm(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BODY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Buttock(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cheek(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Coccygeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cranial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ear(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Elbow(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Eye(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Finger(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fingernail(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fingertip(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Foot(feet)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Forearm(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Forehead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Groin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hand(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Heel(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hip(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Jaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Leg(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Liver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lumbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lung(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Nonclassifiable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Nose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pelvic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pelvis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Prosthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Sacral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Scrotum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Shoulder(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Skull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sole(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Spleen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Stomach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Testis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Thigh(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Thoracic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Toes(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Tooth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Trunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Wrist(s)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0           Abdomen\n",
       "1          Ankle(s)\n",
       "2          Arch(es)\n",
       "3            Arm(s)\n",
       "4              BODY\n",
       "5              Back\n",
       "6             Brain\n",
       "7        Buttock(s)\n",
       "8          Cheek(s)\n",
       "9             Chest\n",
       "10        Coccygeal\n",
       "11          Cranial\n",
       "12           Ear(s)\n",
       "13         Elbow(s)\n",
       "14           Eye(s)\n",
       "15             Face\n",
       "16        Finger(s)\n",
       "17    Fingernail(s)\n",
       "18     Fingertip(s)\n",
       "19             Foot\n",
       "20       Foot(feet)\n",
       "21       Forearm(s)\n",
       "22         Forehead\n",
       "23            Groin\n",
       "24          Hand(s)\n",
       "25             Head\n",
       "26          Heel(s)\n",
       "27           Hip(s)\n",
       "28         Internal\n",
       "29              Jaw\n",
       "..              ...\n",
       "31           Leg(s)\n",
       "32            Liver\n",
       "33            Lower\n",
       "34           Lumbar\n",
       "35          Lung(s)\n",
       "36            Mouth\n",
       "37         Multiple\n",
       "38             Neck\n",
       "39  Nonclassifiable\n",
       "40             Nose\n",
       "41           Pelvic\n",
       "42           Pelvis\n",
       "43       Prosthetic\n",
       "44           Sacral\n",
       "45            Scalp\n",
       "46          Scrotum\n",
       "47      Shoulder(s)\n",
       "48            Skull\n",
       "49          Sole(s)\n",
       "50           Spleen\n",
       "51          Stomach\n",
       "52           Testis\n",
       "53         Thigh(s)\n",
       "54         Thoracic\n",
       "55          Toes(s)\n",
       "56            Tooth\n",
       "57            Trunk\n",
       "58            Upper\n",
       "59            Whole\n",
       "60         Wrist(s)\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.get_dummies(y_dirty).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
