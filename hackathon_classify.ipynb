{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import keras\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>UPA</th>\n",
       "      <th>EventDate</th>\n",
       "      <th>Employer</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Nature</th>\n",
       "      <th>NatureTitle</th>\n",
       "      <th>Part of Body</th>\n",
       "      <th>Part of Body Title</th>\n",
       "      <th>Event</th>\n",
       "      <th>EventTitle</th>\n",
       "      <th>Source</th>\n",
       "      <th>SourceTitle</th>\n",
       "      <th>Secondary Source</th>\n",
       "      <th>Secondary Source Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015010015</td>\n",
       "      <td>931176</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>FCI Otisville Federal Correctional Institution</td>\n",
       "      <td>Two Mile Drive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTISVILLE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>10963.0</td>\n",
       "      <td>41.46</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>Fractures</td>\n",
       "      <td>513</td>\n",
       "      <td>Lower</td>\n",
       "      <td>1214</td>\n",
       "      <td>Injured by physical contact with person while ...</td>\n",
       "      <td>5721</td>\n",
       "      <td>Co-worker</td>\n",
       "      <td>5772.0</td>\n",
       "      <td>Inmate or detainee in custody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015010016</td>\n",
       "      <td>930267</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Kalahari Manufacturing LLC</td>\n",
       "      <td>171 Progress Drive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAKE DELTON</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>53940.0</td>\n",
       "      <td>43.59</td>\n",
       "      <td>...</td>\n",
       "      <td>1522</td>\n",
       "      <td>Second</td>\n",
       "      <td>519</td>\n",
       "      <td>Leg(s)</td>\n",
       "      <td>317</td>\n",
       "      <td>Ignition of vapors, gases, or liquids</td>\n",
       "      <td>7261</td>\n",
       "      <td>Welding, cutting, and blow torches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015010018</td>\n",
       "      <td>929823</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Schneider National Bulk Carrier</td>\n",
       "      <td>420 CORAOPOLIS ROAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORAOPOLIS</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>15108.0</td>\n",
       "      <td>40.49</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Traumatic</td>\n",
       "      <td>9999</td>\n",
       "      <td>Nonclassifiable</td>\n",
       "      <td>4331</td>\n",
       "      <td>Other fall to lower level less than 6 feet</td>\n",
       "      <td>8421</td>\n",
       "      <td>Semi, tractor-trailer, tanker truck</td>\n",
       "      <td>741.0</td>\n",
       "      <td>Ladders-fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015010019</td>\n",
       "      <td>929711</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>PEPSI BOTTLING GROUP INC.</td>\n",
       "      <td>4541 HOUSTON AVE.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MACON</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>31206.0</td>\n",
       "      <td>32.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1972</td>\n",
       "      <td>Soreness</td>\n",
       "      <td>510</td>\n",
       "      <td>Leg(s)</td>\n",
       "      <td>640</td>\n",
       "      <td>Caught in or compressed by equipment or object...</td>\n",
       "      <td>8623</td>\n",
       "      <td>Pallet jack-powered</td>\n",
       "      <td>8420.0</td>\n",
       "      <td>Truck-motorized freight hauling and utility, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015010020</td>\n",
       "      <td>929642</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>North American Pipe Corporation</td>\n",
       "      <td>210 South Arch Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JANESVILLE</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>53545.0</td>\n",
       "      <td>42.67</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>Fractures</td>\n",
       "      <td>4429</td>\n",
       "      <td>Finger(s)</td>\n",
       "      <td>6411</td>\n",
       "      <td>Caught in running equipment or machinery durin...</td>\n",
       "      <td>350</td>\n",
       "      <td>Metal, woodworking, and special material machi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID     UPA EventDate  \\\n",
       "0  2015010015  931176  1/1/2015   \n",
       "1  2015010016  930267  1/1/2015   \n",
       "2  2015010018  929823  1/1/2015   \n",
       "3  2015010019  929711  1/1/2015   \n",
       "4  2015010020  929642  1/1/2015   \n",
       "\n",
       "                                         Employer               Address1  \\\n",
       "0  FCI Otisville Federal Correctional Institution         Two Mile Drive   \n",
       "1                      Kalahari Manufacturing LLC     171 Progress Drive   \n",
       "2                 Schneider National Bulk Carrier    420 CORAOPOLIS ROAD   \n",
       "3                       PEPSI BOTTLING GROUP INC.      4541 HOUSTON AVE.   \n",
       "4                 North American Pipe Corporation  210 South Arch Street   \n",
       "\n",
       "  Address2         City         State      Zip  Latitude  \\\n",
       "0      NaN    OTISVILLE      NEW YORK  10963.0     41.46   \n",
       "1      NaN  LAKE DELTON     WISCONSIN  53940.0     43.59   \n",
       "2      NaN   CORAOPOLIS  PENNSYLVANIA  15108.0     40.49   \n",
       "3      NaN        MACON       GEORGIA  31206.0     32.77   \n",
       "4      NaN   JANESVILLE     WISCONSIN  53545.0     42.67   \n",
       "\n",
       "                         ...                          Nature NatureTitle  \\\n",
       "0                        ...                             111   Fractures   \n",
       "1                        ...                            1522      Second   \n",
       "2                        ...                              10   Traumatic   \n",
       "3                        ...                            1972    Soreness   \n",
       "4                        ...                             111   Fractures   \n",
       "\n",
       "   Part of Body  Part of Body Title  Event  \\\n",
       "0           513               Lower   1214   \n",
       "1           519              Leg(s)    317   \n",
       "2          9999     Nonclassifiable   4331   \n",
       "3           510              Leg(s)    640   \n",
       "4          4429           Finger(s)   6411   \n",
       "\n",
       "                                          EventTitle  Source  \\\n",
       "0  Injured by physical contact with person while ...    5721   \n",
       "1              Ignition of vapors, gases, or liquids    7261   \n",
       "2         Other fall to lower level less than 6 feet    8421   \n",
       "3  Caught in or compressed by equipment or object...    8623   \n",
       "4  Caught in running equipment or machinery durin...     350   \n",
       "\n",
       "                                         SourceTitle  Secondary Source  \\\n",
       "0                                          Co-worker            5772.0   \n",
       "1                 Welding, cutting, and blow torches               NaN   \n",
       "2                Semi, tractor-trailer, tanker truck             741.0   \n",
       "3                                Pallet jack-powered            8420.0   \n",
       "4  Metal, woodworking, and special material machi...               NaN   \n",
       "\n",
       "                              Secondary Source Title  \n",
       "0                      Inmate or detainee in custody  \n",
       "1                                                NaN  \n",
       "2                                      Ladders-fixed  \n",
       "3  Truck-motorized freight hauling and utility, u...  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('severeinjury.csv')\n",
    "df['Part of Body Title'] = [e.split()[0] for e in df['Part of Body Title']]\n",
    "df['Part of Body Title'] = [e.replace(',','') for e in df['Part of Body Title']]\n",
    "df['NatureTitle'] = [e.split()[0] for e in df['NatureTitle']]\n",
    "df['NatureTitle'] = [e.replace(',','') for e in df['NatureTitle']]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dirty = df['Final Narrative']\n",
    "y_body_dirty = df['Part of Body Title']\n",
    "y_nature_dirty = df['NatureTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translations...\n",
      "Lowercasing...\n",
      "Splitting...\n",
      "Fitting....\n",
      "[====================] 100.0%\n",
      "Done fitting!\n",
      "Sequencing....\n",
      "[====================] 100.0%\n",
      "Finished Tokening!\n"
     ]
    }
   ],
   "source": [
    "def clean_sentences(sentences):\n",
    "    translator = str.maketrans('', '', string.punctuation + string.digits)\n",
    "    print('Starting translations...')\n",
    "    sentences = [s.translate(translator) for s in sentences]\n",
    "    stopset = set(nltk.corpus.stopwords.words('english'))\n",
    "    print('Lowercasing...')\n",
    "    tokens = [nltk.wordpunct_tokenize(s.lower()) for s in sentences]\n",
    "    print('Splitting...')\n",
    "    tokens = [np.array(t)[np.invert(np.isin(t, list(stopset)))] for t in tokens]\n",
    "    return np.array(tokens)\n",
    "\n",
    "tokens = clean_sentences(X_dirty)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=1000, oov_token=1)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "    \n",
    "X_all = []\n",
    "\n",
    "count = 0\n",
    "print('Fitting....')\n",
    "for line in tokens:\n",
    "    tokenizer.fit_on_texts(line)\n",
    "    count += 1\n",
    "    if count % 100 == 0 or count == len(X_dirty):\n",
    "        if count != 0:\n",
    "            sys.stdout.write('\\r')\n",
    "        bars = int(count/len(X_dirty)*20)\n",
    "        sys.stdout.write('[{0:20}] {1:4.1%}'.format('='*bars, count/len(X_dirty)))\n",
    "print('\\nDone fitting!')\n",
    "print('Sequencing....')\n",
    "count = 0\n",
    "for line in tokens:\n",
    "    add = [list(np.array(tokenizer.texts_to_sequences(line)).flatten())]\n",
    "    X_all += add\n",
    "    count += 1\n",
    "    if count % 100 == 0 or count == len(X_dirty):\n",
    "        if count != 0:\n",
    "            sys.stdout.write('\\r')\n",
    "        bars = int(count/len(X_dirty)*20)\n",
    "        sys.stdout.write('[{0:20}] {1:4.1%}'.format('='*bars, count/len(X_dirty)))\n",
    "print('\\nFinished Tokening!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Vocab.dat', 'w') as vfile:\n",
    "    vfile.write('{} {}'.format(0, 'x'))\n",
    "    for key, value in sorted(tokenizer.word_index.items(),\n",
    "                                 key=lambda kv: (kv[1], kv[0])):\n",
    "        vfile.write('\\n{} {}'.format(value, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_dict():\n",
    "    vocab_dict = {}\n",
    "    with open('Vocab.dat') as vocab_file:\n",
    "        for line in vocab_file:\n",
    "            (val, key) = line.split()\n",
    "            val = int(val)\n",
    "            if val == 0:\n",
    "                key = ''\n",
    "            vocab_dict[key] = val\n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence_from_dict(sentence, vocab_dict):\n",
    "    tokenized = []\n",
    "    for word in sentence.split():\n",
    "        if word in vocab_dict:\n",
    "            tokenized += [vocab_dict[word]]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_sentence(model, sentence):\n",
    "    vocab_dict = get_vocab_dict()\n",
    "    tokenized = tokenize_sentence_from_dict(sentence, vocab_dict)\n",
    "    return model.predict(np.array([tokenized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_all = np.load('X_all.npy')\n",
    "#y_all = np.load('y_all.npy')\n",
    "\n",
    "X_all = keras.preprocessing.sequence.pad_sequences(X_all, 50)\n",
    "y_body_all = np.array(pd.get_dummies(y_body_dirty))\n",
    "y_nature_all = np.array(pd.get_dummies(y_nature_dirty))\n",
    "\n",
    "np.save('X_all.npy', X_all)\n",
    "np.save('y_body_all.npy', y_body_all)\n",
    "np.save('y_nature_all.npy', y_nature_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(X_all)))\n",
    "np.random.shuffle(indices)\n",
    "num_train = int(.75*len(X_all))\n",
    "\n",
    "X_train = X_all[indices[:num_train]]\n",
    "X_test = X_all[indices[num_train:]]\n",
    "y_body_train = y_body_all[indices[:num_train]]\n",
    "y_body_test = y_body_all[indices[num_train:]]\n",
    "y_nature_train = y_nature_all[indices[:num_train]]\n",
    "y_nature_test = y_nature_all[indices[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_output):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Embedding(12000, 64, mask_zero=True))\n",
    "    model.add(keras.layers.LSTM(64))\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(keras.layers.Dense(num_output, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )   \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16183 samples, validate on 5395 samples\n",
      "Epoch 1/10\n",
      "16183/16183 [==============================] - 35s 2ms/step - loss: 2.3945 - acc: 0.3485 - val_loss: 1.5097 - val_acc: 0.5965\n",
      "Epoch 2/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 1.3247 - acc: 0.6486 - val_loss: 1.0416 - val_acc: 0.7286\n",
      "Epoch 3/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.9369 - acc: 0.7495 - val_loss: 0.8618 - val_acc: 0.7796\n",
      "Epoch 4/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.7419 - acc: 0.7963 - val_loss: 0.8529 - val_acc: 0.7905\n",
      "Epoch 5/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.6198 - acc: 0.8261 - val_loss: 0.7840 - val_acc: 0.8076\n",
      "Epoch 6/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.5385 - acc: 0.8470 - val_loss: 0.8053 - val_acc: 0.8082\n",
      "Epoch 7/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.4665 - acc: 0.8655 - val_loss: 0.8158 - val_acc: 0.8152\n",
      "Epoch 8/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.4296 - acc: 0.8767 - val_loss: 0.8175 - val_acc: 0.8115\n",
      "Epoch 9/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.3690 - acc: 0.8936 - val_loss: 0.8958 - val_acc: 0.8117\n",
      "Epoch 10/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.3468 - acc: 0.9019 - val_loss: 0.9120 - val_acc: 0.8057\n",
      "Train on 16183 samples, validate on 5395 samples\n",
      "Epoch 1/10\n",
      "16183/16183 [==============================] - 35s 2ms/step - loss: 1.7300 - acc: 0.5485 - val_loss: 1.1350 - val_acc: 0.6906\n",
      "Epoch 2/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 1.0313 - acc: 0.7067 - val_loss: 0.8862 - val_acc: 0.7464\n",
      "Epoch 3/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.7966 - acc: 0.7720 - val_loss: 0.8078 - val_acc: 0.7918\n",
      "Epoch 4/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.6382 - acc: 0.8225 - val_loss: 0.7369 - val_acc: 0.8174\n",
      "Epoch 5/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.5221 - acc: 0.8582 - val_loss: 0.7382 - val_acc: 0.8252\n",
      "Epoch 6/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.4558 - acc: 0.8755 - val_loss: 0.7495 - val_acc: 0.8289\n",
      "Epoch 7/10\n",
      "16183/16183 [==============================] - 34s 2ms/step - loss: 0.3947 - acc: 0.8906 - val_loss: 0.8101 - val_acc: 0.8295\n",
      "Epoch 8/10\n",
      "16183/16183 [==============================] - 36s 2ms/step - loss: 0.3374 - acc: 0.9045 - val_loss: 0.7858 - val_acc: 0.8367\n",
      "Epoch 9/10\n",
      "16183/16183 [==============================] - 36s 2ms/step - loss: 0.3121 - acc: 0.9111 - val_loss: 0.8033 - val_acc: 0.8397\n",
      "Epoch 10/10\n",
      "16183/16183 [==============================] - 35s 2ms/step - loss: 0.2754 - acc: 0.9209 - val_loss: 0.8396 - val_acc: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd0dd9b1860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_body = build_model(len(pd.get_dummies(y_body_dirty).columns))\n",
    "model_body.fit(X_train, y_body_train, validation_data=(X_test, y_body_test), epochs=10)\n",
    "\n",
    "model_nature = build_model(len(pd.get_dummies(y_nature_dirty).columns))\n",
    "model_nature.fit(X_train, y_nature_train, validation_data=(X_test, y_nature_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_body.save(\"body_parts2.h5\")\n",
    "model_nature.save(\"nature.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \n",
      "\n",
      "The employee got his foot stuck in a machine. He lost a toe.\n",
      "\n",
      "Prediction: \n",
      "\tBody:   Foot\n",
      "\tNature: Amputations\n",
      "\n",
      "Actual: \n",
      "\tBody:   Eye(s)\n",
      "\tNature: Fractures\n"
     ]
    }
   ],
   "source": [
    "#6405\n",
    "test_idx = 6969\n",
    "test_sentence = df['Final Narrative'][test_idx]\n",
    "test_sentence = 'The employee got his foot stuck in a machine. He lost a toe.'\n",
    "print(\"Sentence: \\n\\n{}\".format(test_sentence))\n",
    "model_body = keras.models.load_model(\"body_parts2.h5\")\n",
    "model_nature = keras.models.load_model(\"nature.h5\")\n",
    "pred_body = predict_from_sentence(model_body, test_sentence)\n",
    "pred_nature = predict_from_sentence(model_nature, test_sentence)\n",
    "idx_body = np.argmax(pred_body)\n",
    "idx_nature = np.argmax(pred_nature)\n",
    "print(\"\\nPrediction: \\n\\tBody:   {}\\n\\tNature: {}\".format(pd.get_dummies(y_body_dirty).columns[idx_body], pd.get_dummies(y_nature_dirty).columns[idx_nature]))\n",
    "print(\"\\nActual: \\n\\tBody:   {}\\n\\tNature: {}\".format(df['Part of Body Title'][test_idx], df['NatureTitle'][test_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three correctional facility guards were escorting a restrained federal prison inmate when he became disruptive, requiring the use of force. \n",
      "Two guards and the inmate fell onto the Lieutenant's right leg, fracturing his fibula. He was transported to the hospital and released the following day. \n",
      "\n",
      "An employee was struck by an excavator on 01/02/2015 and hospitalized for injuries to his leg, several broken bones in his foot, and a fracture in his left arm.\n"
     ]
    }
   ],
   "source": [
    "print(df['Final Narrative'][0], '\\n')\n",
    "print(df['Final Narrative'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
